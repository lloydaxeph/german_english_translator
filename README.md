# German-English Translator using Multi-Head Self-Attention Transformer

## 1.0 About
This project aims to train and use a multi-head attention transformer model to translate **German** text to **English**.
Dataset that will be used in this implemenation is the [Multi30k dataset](https://github.com/multi30k/dataset).
The model that will be used is the [Multi-Head Self-Attention Transformer ](https://github.com/lloydaxeph/multi_head_attention_transformer) model I created from scratch.

## 2.0 Getting Started
### 2.1 Installation
Install the required packages.
```
pip3 install -r requirements.txt
```
### 2.2 Clone Model
Copy or clone the model from my repository.
```
git clone https://github.com/lloydaxeph/multi_head_attention_transformer
```

For the complete demonstration, you can follow the [sample_implementation.py](https://github.com/lloydaxeph/german_english_translator/blob/master/sample_implementation.py) script above.





